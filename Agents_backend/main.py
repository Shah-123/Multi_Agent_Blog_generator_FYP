import os
import sys
import json
import re
from datetime import date, datetime
from pathlib import Path
from dotenv import load_dotenv

# Environment Setup
load_dotenv()
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ERROR: OPENAI_API_KEY not found in .env file.")
    sys.exit(1)

# LangGraph Imports
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver 
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

# Internal Imports
from Graph.state import State, Plan
from Graph.nodes import (
    router_node, 
    research_node, 
    orchestrator_node, 
    worker_node, 
    fanout, 
    merge_content, 
    decide_images, 
    generate_and_place_images,
    fact_checker_node, 
    social_media_node, 
    evaluator_node,
    _safe_slug
)
from validators import TopicValidator

# ===========================================================================
# PODCAST IMPORT WITH FALLBACK
# ===========================================================================
try:
    from Graph.podcast_studio import podcast_node
    PODCAST_AVAILABLE = True
except ImportError:
    PODCAST_AVAILABLE = False
    def podcast_node(state: dict) -> dict:
        return {"audio_path": None, "script_path": None}

# ===========================================================================
# 1. HELPER FUNCTIONS
# ===========================================================================

def create_blog_structure(topic: str) -> dict:
    """Creates organized folder structure for the blog."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_topic = _safe_slug(topic)[:50]
    
    base_folder = f"blogs/{safe_topic}_{timestamp}"
    
    folders = {
        "base": base_folder,
        "content": f"{base_folder}/content",
        "social": f"{base_folder}/social_media",
        "reports": f"{base_folder}/reports",
        "assets": f"{base_folder}/assets/images",
        "research": f"{base_folder}/research",
        "audio": f"{base_folder}/audio",
        "metadata": f"{base_folder}/metadata"
    }
    
    for path in folders.values():
        Path(path).mkdir(parents=True, exist_ok=True)
        
    return folders

def refine_plan_with_llm(current_plan: Plan, feedback: str) -> Plan:
    """Refines the plan based on human feedback."""
    print(f"\n   ğŸ¤– Refining plan based on: '{feedback}'...")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    editor = llm.with_structured_output(Plan)
    
    return editor.invoke([
        SystemMessage(content="You are a helpful editor. Update the Plan based STRICTLY on user feedback."),
        HumanMessage(content=f"Current Plan:\n{current_plan.model_dump_json()}\n\nFeedback: {feedback}")
    ])

def generate_readme(folders: dict, saved_files: dict, state: State) -> str:
    """Generates a README.md file summarizing the project generation."""
    topic = state.get("topic", "Unknown Topic")
    score = state.get("quality_evaluation", {}).get("final_score", "N/A")
    
    md = f"""# Blog Project: {topic}
**Generated on:** {datetime.now().strftime('%Y-%m-%d %H:%M')}
**Quality Score:** {score}/10

## ğŸ“‚ Project Structure
This folder contains all assets generated by the AI Content Factory.

### ğŸ“„ Content
- **Main Blog:** [`{os.path.basename(saved_files.get('blog', ''))}`](./content/)
- **Clean Markdown:** [`{os.path.basename(saved_files.get('blog_clean', ''))}`](./content/)

### ğŸ“± Social Media
- LinkedIn, YouTube, and Facebook drafts located in [`/social_media`](./social_media/)

### ğŸ“Š Reports
- **Fact Check:** [`fact_check.txt`](./reports/fact_check.txt)
- **Quality Eval:** [`quality_evaluation.json`](./reports/quality_evaluation.json)

### ğŸ™ï¸ Multimedia
- **Podcast Audio:** { "âœ… Available in /audio" if saved_files.get("audio") else "âŒ Not generated" }
- **Images:** { "âœ… Available in /assets" if state.get("image_specs") else "âŒ Not generated" }

## ğŸ” Research Context
- **Mode:** {state.get("mode")}
- **Evidence Items:** {len(state.get("evidence", []))} source(s) used.
"""
    readme_path = f"{folders['base']}/README.md"
    Path(readme_path).write_text(md, encoding="utf-8")
    return readme_path

def save_blog_content(folders: dict, state: State) -> dict:
    """Saves all outputs to their respective folders."""
    saved = {}
    plan = state.get("plan")
    if not plan: return saved

    slug = _safe_slug(plan.blog_title)

    # 1. Content
    if state.get("final"):
        path = f"{folders['content']}/{slug}.md"
        Path(path).write_text(state["final"], encoding="utf-8")
        saved["blog"] = path
    
    if state.get("merged_md"):
        path = f"{folders['content']}/{slug}_clean.md"
        Path(path).write_text(state["merged_md"], encoding="utf-8")
        saved["blog_clean"] = path

    # 2. Social
    for platform in ["linkedin", "facebook"]:
        key = f"{platform}_post"
        if state.get(key):
            path = f"{folders['social']}/{platform}_{slug}.txt"
            Path(path).write_text(state[key], encoding="utf-8")
            saved[platform] = path
            
    if state.get("youtube_script"):
        path = f"{folders['social']}/youtube_{slug}.txt"
        Path(path).write_text(state["youtube_script"], encoding="utf-8")
        saved["youtube"] = path

    # 3. Reports
    if state.get("fact_check_report"):
        path = f"{folders['reports']}/fact_check.txt"
        Path(path).write_text(state["fact_check_report"], encoding="utf-8")
        saved["fact_check"] = path
        
    if state.get("quality_evaluation"):
        path = f"{folders['reports']}/quality_evaluation.json"
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(state["quality_evaluation"], f, indent=2)
        saved["quality_eval"] = path

    # 4. Audio
    if state.get("audio_path") and os.path.exists(state["audio_path"]):
        import shutil
        dest = f"{folders['audio']}/podcast.mp3"
        shutil.copy(state["audio_path"], dest)
        saved["audio"] = dest
        # Also save script
        if state.get("script_path"):
            shutil.copy(state["script_path"], f"{folders['audio']}/script.txt")

    # 5. Metadata
    meta = {
        "topic": state.get("topic"),
        "date": datetime.now().isoformat(),
        "mode": state.get("mode"),
        "plan": plan.model_dump()
    }
    with open(f"{folders['metadata']}/metadata.json", 'w') as f:
        json.dump(meta, f, indent=2)

    return saved

# ===========================================================================
# 2. BUILD GRAPH
# ===========================================================================
def build_graph():
    # Subgraph for Reducer (Images -> Merge)
    reducer = StateGraph(State)
    reducer.add_node("merge_content", merge_content)
    reducer.add_node("decide_images", decide_images)
    reducer.add_node("generate_and_place_images", generate_and_place_images)
    reducer.add_edge(START, "merge_content")
    reducer.add_edge("merge_content", "decide_images")
    reducer.add_edge("decide_images", "generate_and_place_images")
    reducer.add_edge("generate_and_place_images", END)

    # Main Graph
    workflow = StateGraph(State)
    workflow.add_node("router", router_node)
    workflow.add_node("research", research_node)
    workflow.add_node("orchestrator", orchestrator_node)
    workflow.add_node("worker", worker_node)
    workflow.add_node("reducer", reducer.compile()) 
    workflow.add_node("fact_checker", fact_checker_node)
    workflow.add_node("social_media", social_media_node)
    
    # Conditional Podcast Node
    if PODCAST_AVAILABLE:
        workflow.add_node("audio_generator", podcast_node)
    else:
        workflow.add_node("audio_generator", lambda s: {})
    
    workflow.add_node("evaluator", evaluator_node)

    # Edges
    workflow.add_edge(START, "router")
    workflow.add_conditional_edges("router", 
        lambda s: "research" if s["needs_research"] else "orchestrator"
    )
    workflow.add_edge("research", "orchestrator")
    workflow.add_conditional_edges("orchestrator", fanout, ["worker"])
    workflow.add_edge("worker", "reducer")
    workflow.add_edge("reducer", "fact_checker")
    workflow.add_edge("fact_checker", "social_media")
    workflow.add_edge("social_media", "audio_generator")
    workflow.add_edge("audio_generator", "evaluator")
    workflow.add_edge("evaluator", END)

    return workflow.compile(
        checkpointer=MemorySaver(), 
        interrupt_after=["orchestrator"]
    )

# ===========================================================================
# 3. MAIN RUNNER
# ===========================================================================
def run_app():
    print("="*80)
    print("ğŸš€ AI CONTENT FACTORY (FYP EDITION)")
    print("="*80)
    
    # 1. Input & Validation
    topic = input("\nğŸ“ Enter blog topic: ").strip()
    if not topic: return
    
    valid = TopicValidator().validate(topic)
    if not valid["valid"]:
        print(f"âŒ Rejected: {valid['reason']}")
        return
    
    print(f"âœ… Topic Accepted: {topic}")
    
    # 2. Setup Folders
    folders = create_blog_structure(topic)
    print(f"ğŸ“ Working Directory: {folders['base']}")
    
    # 3. Graph Config
    app = build_graph()
    thread = {"configurable": {"thread_id": f"job_{datetime.now().strftime('%M%S')}"}}
    initial_state = {
        "topic": topic,
        "as_of": date.today().isoformat(),
        "sections": [],
        "blog_folder": folders["base"]
    }
    
    # 4. Phase 1: Research & Planning
    print("\nğŸš€ PHASE 1: RESEARCH & PLANNING")
    for _ in app.stream(initial_state, thread, stream_mode="values"): pass
    
    # 5. Human-in-the-Loop Review
    state = app.get_state(thread).values
    plan = state.get("plan")
    
    print("\n" + "="*40)
    print(f"ğŸ“‹ DRAFT PLAN: {plan.blog_title}")
    print("="*40)
    for t in plan.tasks:
        print(f"   {t.id}. {t.title}")
    
    while True:
        feedback = input("\nApproved? (y/n): ").lower()
        if feedback == 'y': break
        elif feedback == 'n':
            notes = input("Enter changes: ")
            new_plan = refine_plan_with_llm(plan, notes)
            app.update_state(thread, {"plan": new_plan})
            plan = new_plan # Update local var for display
            print("\nâœ… Plan Updated.")
            for t in plan.tasks: print(f"   - {t.title}")
    
    # 6. Phase 2: Execution
    print("\nğŸš€ PHASE 2: WRITING & PRODUCTION")
    # Resume from interruption
    for _ in app.stream(None, thread, stream_mode="values", recursion_limit=150): pass
    
    # 7. Final Saving
    final_state = app.get_state(thread).values
    print("\nğŸ’¾ SAVING ASSETS...")
    saved_files = save_blog_content(folders, final_state)
    readme = generate_readme(folders, saved_files, final_state)
    
    print("\n" + "="*80)
    print("âœ¨ GENERATION COMPLETE âœ¨")
    print(f"ğŸ“‚ Output Folder: {folders['base']}")
    print(f"ğŸ“– Read Summary: {readme}")
    print("="*80)

if __name__ == "__main__":
    run_app()