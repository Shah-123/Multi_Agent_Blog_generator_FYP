from typing import List, Literal
from pydantic import BaseModel, Field

# ============================================================================
# QA AGENT SCHEMAS (COMBINED FACT, COMPLETION, EVALUATION)
# ============================================================================

class QAIssue(BaseModel):
    """A single issue found during the QA audit."""
    claim: str = Field(description="The statement or section in the blog that is problematic")
    issue_type: Literal["fact_error", "hallucination", "missing_content", "poor_flow", "other"] = Field(
        description="Category of the issue"
    )
    severity: Literal["critical", "minor", "suggestion"] = Field(
        default="minor",
        description="critical=must fix, minor=should fix, suggestion=optional"
    )
    recommendation: str = Field(description="Actionable instruction on how to fix the issue")

class QAReport(BaseModel):
    """The full, unified audit report generated by the QA Agent."""
    depth_score: float = Field(description="Score 0-10 on how comprehensively and accurately the topic is covered. Penalize fluffy content.")
    structure_score: float = Field(description="Score 0-10 on logical flow, headers, and paragraph sizing.")
    readability_score: float = Field(description="Score 0-10 on human-like tone, sentence variety, and avoiding AI cliches.")
    overall_score: float = Field(description="Score 0-10 representing the final, overall quality grade.")
    
    verdict: Literal["READY", "NEEDS_REVISION"] = Field(
        description="Final decision on publication status. Only choose NEEDS_REVISION if there are critical fact or completion issues."
    )
    
    issues: List[QAIssue] = Field(
        description="List of issues found (empty if clean)", default=[]
    )
    
    strengths: List[str] = Field(description="2-3 specific strengths of this article.")